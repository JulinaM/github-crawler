{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " #!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "MAX_LEN = 512\n",
    "EPOCHS = 10\n",
    "RANDOM_SEED = 42\n",
    "model_name = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS connecting to Cloudant db github-public-ai-2022\n"
     ]
    }
   ],
   "source": [
    "from utils.cloudant_utils import cloudant_db as db\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import difflib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from torch import nn\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from readme_cleanup import readme_cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "repos = [r for r in db.get_query_result({\"type\": \"release\"}, [\"_id\", \"releases\"], limit=10000, raw_result=True)[\"docs\"]]\n",
    "values = [r for release in repos for r in release[\"releases\"]]\n",
    "df = pd.DataFrame(values)\n",
    "df['contributors'] = df['contributors'].apply(lambda x:\n",
    "                                              [i for i in x if i is not None] if isinstance(x, list)\n",
    "                                              else [])\n",
    "df = df[~df['readme'].isnull()]\n",
    "new_df = df.groupby(\"repo\").agg({\"readme\": list,\n",
    "                                 \"stars\": sum,\n",
    "                                 \"forks\": sum,\n",
    "                                 \"downloads\": sum,\n",
    "                                 \"contributors\": sum})\n",
    "new_df['600stars']= np.where(new_df['stars'] > 600, 1, 0)\n",
    "new_df = new_df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def diff_calculator(str1, str2):\n",
    "   s = difflib.SequenceMatcher(lambda x : x == '')\n",
    "   s.set_seqs(str1, str2)\n",
    "   i = 1\n",
    "   # codes = []\n",
    "   # delete = []\n",
    "   # replace = {}\n",
    "   insert = []\n",
    "   for (opcode, before_start, before_end, after_start, after_end) in s.get_opcodes():\n",
    "       if opcode == 'equal':\n",
    "           continue\n",
    "       # codes.append(opcode)\n",
    "       # # print (i, \". %7s '%s :'  ----->  '%s'\" % (opcode, test[0][before_start:before_end], test[1][after_start:after_end]))\n",
    "       # if opcode == 'replace':\n",
    "       #     replace[str1[before_start:before_end]]  = str2[after_start:after_end]\n",
    "       # if opcode == 'delete':\n",
    "       #     delete.append(str1[before_start:before_end])\n",
    "       if opcode == 'insert':\n",
    "           if str2[after_start:after_end]:\n",
    "            insert.append(str2[after_start:after_end])\n",
    "       i = i + 1\n",
    "   # return replace, delete, insert\n",
    "   return insert\n",
    "\n",
    "def create_a_sequence(readmeList):\n",
    "    result = []\n",
    "    for i in range(0,len(readmeList)-1):\n",
    "        first = readme_cleanup(readmeList[i])\n",
    "        second = readme_cleanup(readmeList[i+1])\n",
    "        insert = diff_calculator(first, second)\n",
    "        result.append(','.join(insert))\n",
    "    return result\n",
    "\n",
    "def prepareSequenceForBERT(readmeList):\n",
    "    diffList = create_a_sequence(readmeList)\n",
    "    s = '[CLS]' + \"[SEP]\".join([str(i) for i in diffList])\n",
    "    return s +'[SEP]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# len(new_df.iloc[1]['readme']), prepareSequenceForBERT(new_df.iloc[1]['readme'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((60, 6), (20, 6), (20, 6))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "df_train, df_test = train_test_split(new_df, test_size=0.4, random_state=RANDOM_SEED)\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ReadmeDataSet(Dataset):\n",
    "   def __init__(self, _df, tokenizer, max_len):\n",
    "      self._df = _df\n",
    "      self.tokenizer = tokenizer\n",
    "      self.max_len = max_len\n",
    "\n",
    "   def __len__(self):\n",
    "      return len(self._df)\n",
    "\n",
    "   def __getitem__(self, item):\n",
    "      _sequence = prepareSequenceForBERT(self._df.iloc[item]['readme'])\n",
    "      target = self._df.iloc[item]['600stars']\n",
    "      encoding = self.tokenizer.encode_plus(_sequence,\n",
    "                                     None,\n",
    "                                     max_length = self.max_len,\n",
    "                                     truncation=True,\n",
    "                                     add_special_tokens=True,\n",
    "#                                      padding=MAX_LEN,\n",
    "#                                      padding='longest',\n",
    "                                     pad_to_max_length=True,\n",
    "                                     return_token_type_ids=True)\n",
    "\n",
    "      return {\n",
    "      'sequence': _sequence,\n",
    "      'input_ids': torch.tensor(encoding.input_ids, dtype=torch.long),\n",
    "      'attention_mask':  torch.tensor(encoding.attention_mask, dtype=torch.long),\n",
    "      'token_type_ids': torch.tensor(encoding.token_type_ids, dtype=torch.long),\n",
    "      'targets': torch.tensor(target, dtype=torch.long)\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_data_loader(_df, tokenizer, max_len, batch_size):\n",
    "   ds = ReadmeDataSet(_df = _df, tokenizer=tokenizer, max_len=max_len)\n",
    "   return DataLoader(ds, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Import BERT Tokenizer and BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "bert_model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
    "                                                      num_labels=2,\n",
    "                                                      output_attentions= False,\n",
    "                                                      output_hidden_states= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "read_me_list = new_df['readme'].tolist()\n",
    "# read_me_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  31456\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for sentences in read_me_list:\n",
    "    for sent in sentences:\n",
    "        if sent:\n",
    "            input_ids = bert_tokenizer.encode(sent, add_special_tokens=True)\n",
    "            max_len = max(max_len, len(input_ids))\n",
    "print('Max sentence length: ', max_len)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "1     [CLS][SEP]M[SEP][SEP][SEP][SEP][SEP][SEP][SEP]...\n2     [CLS][SEP]S[SEP][SEP][SEP][SEP][SEP][SEP][SEP]...\n3     [CLS][SEP][SEP]K[SEP][SEP][SEP][SEP][SEP][SEP]...\n4     [CLS][SEP]![SEP][SEP][SEP][SEP][SEP][SEP][SEP]...\n5     [CLS][SEP]![SEP][SEP][SEP][SEP][SEP][SEP][SEP]...\n6     [CLS][SEP]![SEP][SEP][SEP][SEP][SEP][SEP][SEP]...\n7     [CLS][SEP]![SEP][SEP][SEP][SEP][SEP][SEP][SEP]...\n8     [CLS][SEP]![SEP][SEP][SEP][SEP][SEP][SEP][SEP]...\n9     [CLS][SEP]![SEP][SEP][SEP][SEP][SEP][SEP][SEP]...\n10    [CLS][SEP]![SEP][SEP][SEP][SEP][SEP][SEP][SEP]...\ndtype: object"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df[:10]\n",
    "X = sample.apply(lambda row : prepareSequenceForBERT(row['readme']), axis = 1)\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot index by location index with a non-integer key",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m inputDS \u001B[38;5;241m=\u001B[39m ReadmeDataSet(df, bert_tokenizer, \u001B[38;5;241m512\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m X \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(\u001B[43minputDS\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msequence\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m)\n\u001B[1;32m      3\u001B[0m X\u001B[38;5;241m.\u001B[39mshape\n",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36mReadmeDataSet.__getitem__\u001B[0;34m(self, item)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, item):\n\u001B[0;32m---> 11\u001B[0m    _sequence \u001B[38;5;241m=\u001B[39m prepareSequenceForBERT(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m]\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreadme\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     12\u001B[0m    target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_df\u001B[38;5;241m.\u001B[39miloc[item][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m600stars\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     13\u001B[0m    encoding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer\u001B[38;5;241m.\u001B[39mencode_plus(_sequence,\n\u001B[1;32m     14\u001B[0m                                   \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     15\u001B[0m                                   max_length \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_len,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     20\u001B[0m                                   pad_to_max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     21\u001B[0m                                   return_token_type_ids\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/PycharmProjects/github-crawler/env/lib/python3.9/site-packages/pandas/core/indexing.py:967\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    964\u001B[0m axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    966\u001B[0m maybe_callable \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mapply_if_callable(key, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj)\n\u001B[0;32m--> 967\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmaybe_callable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/github-crawler/env/lib/python3.9/site-packages/pandas/core/indexing.py:1517\u001B[0m, in \u001B[0;36m_iLocIndexer._getitem_axis\u001B[0;34m(self, key, axis)\u001B[0m\n\u001B[1;32m   1515\u001B[0m key \u001B[38;5;241m=\u001B[39m item_from_zerodim(key)\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_integer(key):\n\u001B[0;32m-> 1517\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot index by location index with a non-integer key\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1519\u001B[0m \u001B[38;5;66;03m# validate the location\u001B[39;00m\n\u001B[1;32m   1520\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_integer(key, axis)\n",
      "\u001B[0;31mTypeError\u001B[0m: Cannot index by location index with a non-integer key"
     ]
    }
   ],
   "source": [
    "inputDS = ReadmeDataSet(df, bert_tokenizer, 512)\n",
    "df['cleanreadme'] = df.apply(lambda row : prepareSequenceForBERT(row['readme']), axis = 1)\n",
    "X = df['cleanreadme']\n",
    "X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlda\u001B[39;00m\n\u001B[1;32m      2\u001B[0m model \u001B[38;5;241m=\u001B[39m lda\u001B[38;5;241m.\u001B[39mLDA(n_topics\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m, n_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1500\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/github-crawler/env/lib/python3.9/site-packages/lda/lda.py:130\u001B[0m, in \u001B[0;36mLDA.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    117\u001B[0m     \u001B[38;5;124;03m\"\"\"Fit the model with X.\u001B[39;00m\n\u001B[1;32m    118\u001B[0m \n\u001B[1;32m    119\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;124;03m        Returns the instance itself.\u001B[39;00m\n\u001B[1;32m    129\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 130\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/github-crawler/env/lib/python3.9/site-packages/lda/lda.py:243\u001B[0m, in \u001B[0;36mLDA._fit\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    241\u001B[0m random_state \u001B[38;5;241m=\u001B[39m lda\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheck_random_state(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_state)\n\u001B[1;32m    242\u001B[0m rands \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_rands\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m--> 243\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_initialize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    244\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m it \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_iter):\n\u001B[1;32m    245\u001B[0m     \u001B[38;5;66;03m# FIXME: using numpy.roll with a random shift might be faster\u001B[39;00m\n\u001B[1;32m    246\u001B[0m     random_state\u001B[38;5;241m.\u001B[39mshuffle(rands)\n",
      "File \u001B[0;32m~/PycharmProjects/github-crawler/env/lib/python3.9/site-packages/lda/lda.py:269\u001B[0m, in \u001B[0;36mLDA._initialize\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    268\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_initialize\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m--> 269\u001B[0m     D, W \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m    270\u001B[0m     N \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(X\u001B[38;5;241m.\u001B[39msum())\n\u001B[1;32m    271\u001B[0m     n_topics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_topics\n",
      "\u001B[0;31mValueError\u001B[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "import lda\n",
    "model = lda.LDA(n_topics=20, n_iter=1500, random_state=1)\n",
    "model.fit(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topic_word = model.topic_word_\n",
    "n_top_words = 8\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(X)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 6), (60, 6), (20, 6), (20, 6))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_loader = create_data_loader(df_train, bert_tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, bert_tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, bert_tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "new_df.shape, df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for d in train_data_loader:\n",
    "#     input_ids = d[\"input_ids\"].to(device)\n",
    "#     attention_mask = d[\"attention_mask\"].to(device)\n",
    "#     targets = d[\"targets\"].to(device)\n",
    "#     print(d[\"input_ids\"].shape)\n",
    "# len(val_data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TEST the tokenizer and data loader\n",
    "# sequence = prepareSequenceForBERT(new_df.iloc[1]['readme'])\n",
    "# label = new_df.iloc[2]['600stars']\n",
    "# tokens = bert_tokenizer.encode_plus(\n",
    "#             sequence,\n",
    "#             None,\n",
    "#             max_length= 512,\n",
    "#             truncation=True,\n",
    "#             add_special_tokens=True,\n",
    "# #             pad_to_max_length=True,\n",
    "#             padding = True,\n",
    "#             return_token_type_ids=True\n",
    "#         )\n",
    "# print(f' Sentence: {sequence}')\n",
    "# print(f' Tokens: {tokens}')\n",
    "# print(f' Tokens.token_type_ids: {tokens.token_type_ids}')\n",
    "# print(f' Tokens.input_ids: {len(tokens.input_ids)}')\n",
    "# output = {\n",
    "#       'input_ids': torch.tensor(tokens.input_ids, dtype=torch.long),\n",
    "#       'attention_mask':  torch.tensor(tokens.attention_mask, dtype=torch.long),\n",
    "#       'token_type_ids': torch.tensor(tokens.token_type_ids, dtype=torch.long),\n",
    "#       'targets': torch.tensor(label, dtype=torch.long)\n",
    "#     }\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julinamaharjan/PycharmProjects/github-crawler/env/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(bert_model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "# loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch( model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "  model = model.train()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  for d in data_loader:\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    targets = d[\"targets\"].to(device)\n",
    "\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "\n",
    "    _, preds = torch.max(outputs.logits, dim=1)\n",
    "    loss = loss_fn(outputs.logits, targets)\n",
    "\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  model = model.eval()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs.logits, dim=1)\n",
    "\n",
    "      loss = loss_fn(outputs.logits, targets)\n",
    "\n",
    "      correct_predictions += torch.sum(preds == targets)\n",
    "      losses.append(loss.item())\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julinamaharjan/PycharmProjects/github-crawler/env/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train loss 0.3004196286201477 accuracy 0.9166666666666666\n",
      "Val   loss 0.13683850690722466 accuracy 0.95\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train loss 0.18011835310608149 accuracy 0.9333333333333333\n",
      "Val   loss 0.14710313826799393 accuracy 0.95\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train loss 0.130374850705266 accuracy 0.9333333333333333\n",
      "Val   loss 0.12100890278816223 accuracy 0.95\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train loss 0.10133744310587645 accuracy 0.9333333333333333\n",
      "Val   loss 0.10634927451610565 accuracy 0.95\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train loss 0.07862597063649446 accuracy 0.95\n",
      "Val   loss 0.1610282063484192 accuracy 0.95\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train loss 0.06008679635124281 accuracy 0.95\n",
      "Val   loss 0.1485648863017559 accuracy 0.95\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train loss 0.049081339995609596 accuracy 0.95\n",
      "Val   loss 0.12847472727298737 accuracy 0.95\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train loss 0.050877975969342515 accuracy 0.95\n",
      "Val   loss 0.12819460593163967 accuracy 0.95\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Train loss 0.04041993914870545 accuracy 0.9833333333333333\n",
      "Val   loss 0.12658719718456268 accuracy 0.95\n",
      "\n",
      "CPU times: user 1h 32min 33s, sys: 11min 37s, total: 1h 44min 10s\n",
      "Wall time: 3h 55min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = defaultdict(list)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    bert_model,\n",
    "    train_data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    len(df_train)\n",
    "  )\n",
    "\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "  val_acc, val_loss = eval_model(\n",
    "    bert_model,\n",
    "    val_data_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(df_val)\n",
    "  )\n",
    "\n",
    "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "  print()\n",
    "\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "\n",
    "  if val_acc > best_accuracy:\n",
    "    current_time = datetime.now().strftime(\"%Y_%m_%d-%I_%M%p\")\n",
    "    torch.save(bert_model.state_dict(), 'best_model_state' + current_time+'.bin')\n",
    "    best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc, _ = eval_model(bert_model, test_data_loader, loss_fn, device, len(df_test))\n",
    "test_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "  model = model.eval()\n",
    "\n",
    "  sequences = []\n",
    "  predictions = []\n",
    "  prediction_probs = []\n",
    "  real_values = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "\n",
    "      texts = d[\"sequence\"]\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      token_type_ids = d[\"token_type_ids\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "\n",
    "      outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "\n",
    "      _, preds = torch.max(outputs.logits, dim=1)\n",
    "      probs = F.softmax(outputs.logits, dim=1)\n",
    "\n",
    "      sequences.extend(texts)\n",
    "      predictions.extend(preds)\n",
    "      prediction_probs.extend(probs)\n",
    "      real_values.extend(targets)\n",
    "\n",
    "  predictions = torch.stack(predictions).cpu()\n",
    "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "  real_values = torch.stack(real_values).cpu()\n",
    "  return outputs, sequences, predictions, prediction_probs, real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julinamaharjan/PycharmProjects/github-crawler/env/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2301: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "outputss, y_sequences, y_pred, y_pred_probs, y_test = get_predictions(bert_model, val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logit_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_test.numpy(), y_pred_probs[:, 1:].numpy())\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC_'+ current_time +'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([0.        , 0.05263158, 0.10526316, 0.10526316, 0.63157895,\n        0.78947368, 1.        ]),\n array([0., 0., 0., 1., 1., 1., 1.]),\n array([1.21246111e+00, 2.12461069e-01, 1.02780305e-01, 3.57354097e-02,\n        7.61162606e-04, 7.33732188e-04, 7.33731838e-04], dtype=float32))"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xq/pylr4t8d08g_cywhg3hhf02w0000gn/T/ipykernel_72783/2889840059.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  npa = np.asarray(someListOfLists)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                               readme  Real  Predicted  \\\n0   [CLS]Install with Docker\\n,directly in the con...     0          0   \n1   [CLS]EvenVizion - is a video-based camera loca...     0          0   \n2                                          [CLS][SEP]     0          0   \n3                                          [CLS][SEP]     0          0   \n4                                          [CLS][SEP]     0          0   \n5   [CLS][SEP][SEP][SEP] Citation\\nPlease use the...     0          0   \n6   [CLS] ,\\ntry a another image (mirror.baidubce....     1          0   \n7                                          [CLS][SEP]     0          0   \n8                                [CLS][SEP][SEP][SEP]     0          0   \n9   [CLS]\\nInstallation\\nClone the repo\\nInstall r...     0          0   \n10  [CLS][SEP][SEP]/v4[SEP][SEP][SEP][SEP][SEP]Go ...     0          0   \n11  [CLS]New Release version 0.7.0\\nTensorboard su...     0          0   \n12                                         [CLS][SEP]     0          0   \n13  [CLS]Command Line Interface\\nA command line in...     0          0   \n14  [CLS]imulink, tool chains and compiler,Models ...     0          0   \n15                                         [CLS][SEP]     0          0   \n16  [CLS]\\nFrom AutoML-Benchmark ,:\\n01_Quick_Star...     0          0   \n17  [CLS] The automated machine learning pipeline ...     0          0   \n18  [CLS] Thanks to Ilyes and Kvin for the PR\\nIl...     0          0   \n19                                         [CLS][SEP]     0          0   \n\n    Pred-prob              All Pred-probs  \n0    0.002230   [0.99776983, 0.002230199]  \n1    0.001103   [0.9988971, 0.0011029042]  \n2    0.000734  [0.9992662, 0.00073373184]  \n3    0.000734   [0.9992662, 0.0007337322]  \n4    0.000734  [0.9992662, 0.00073373184]  \n5    0.000761  [0.99923885, 0.0007611626]  \n6    0.035735     [0.9642646, 0.03573541]  \n7    0.000734   [0.9992662, 0.0007337322]  \n8    0.000771   [0.9992292, 0.0007707568]  \n9    0.212461    [0.78753895, 0.21246107]  \n10   0.003239   [0.99676055, 0.003239427]  \n11   0.015620     [0.9843805, 0.01561951]  \n12   0.000734  [0.9992662, 0.00073373184]  \n13   0.001605   [0.9983948, 0.0016051709]  \n14   0.000827  [0.99917334, 0.0008266301]  \n15   0.000734   [0.9992662, 0.0007337322]  \n16   0.002207   [0.9977931, 0.0022068887]  \n17   0.102780    [0.8972197, 0.102780305]  \n18   0.001012  [0.99898833, 0.0010116681]  \n19   0.000734  [0.9992662, 0.00073373184]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>readme</th>\n      <th>Real</th>\n      <th>Predicted</th>\n      <th>Pred-prob</th>\n      <th>All Pred-probs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[CLS]Install with Docker\\n,directly in the con...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.002230</td>\n      <td>[0.99776983, 0.002230199]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[CLS]EvenVizion - is a video-based camera loca...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.001103</td>\n      <td>[0.9988971, 0.0011029042]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[CLS][SEP]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000734</td>\n      <td>[0.9992662, 0.00073373184]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[CLS][SEP]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000734</td>\n      <td>[0.9992662, 0.0007337322]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[CLS][SEP]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000734</td>\n      <td>[0.9992662, 0.00073373184]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[CLS][SEP][SEP][SEP] Citation\\nPlease use the...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000761</td>\n      <td>[0.99923885, 0.0007611626]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[CLS] ,\\ntry a another image (mirror.baidubce....</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.035735</td>\n      <td>[0.9642646, 0.03573541]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[CLS][SEP]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000734</td>\n      <td>[0.9992662, 0.0007337322]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[CLS][SEP][SEP][SEP]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000771</td>\n      <td>[0.9992292, 0.0007707568]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[CLS]\\nInstallation\\nClone the repo\\nInstall r...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.212461</td>\n      <td>[0.78753895, 0.21246107]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>[CLS][SEP][SEP]/v4[SEP][SEP][SEP][SEP][SEP]Go ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.003239</td>\n      <td>[0.99676055, 0.003239427]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>[CLS]New Release version 0.7.0\\nTensorboard su...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.015620</td>\n      <td>[0.9843805, 0.01561951]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>[CLS][SEP]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000734</td>\n      <td>[0.9992662, 0.00073373184]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>[CLS]Command Line Interface\\nA command line in...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.001605</td>\n      <td>[0.9983948, 0.0016051709]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>[CLS]imulink, tool chains and compiler,Models ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000827</td>\n      <td>[0.99917334, 0.0008266301]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>[CLS][SEP]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000734</td>\n      <td>[0.9992662, 0.0007337322]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>[CLS]\\nFrom AutoML-Benchmark ,:\\n01_Quick_Star...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.002207</td>\n      <td>[0.9977931, 0.0022068887]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>[CLS] The automated machine learning pipeline ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.102780</td>\n      <td>[0.8972197, 0.102780305]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>[CLS] Thanks to Ilyes and Kvin for the PR\\nIl...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.001012</td>\n      <td>[0.99898833, 0.0010116681]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>[CLS][SEP]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.000734</td>\n      <td>[0.9992662, 0.00073373184]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_probs_pd = [y.numpy() for y in y_pred_probs]\n",
    "someListOfLists = list(zip(y_sequences, y_test.numpy(), y_pred.numpy(), y_pred_probs[:, 1:].numpy().squeeze(), y_pred_probs_pd ))\n",
    "npa = np.asarray(someListOfLists)\n",
    "dff = pd.DataFrame(someListOfLists, columns = ['readme', 'Real', 'Predicted', 'Pred-prob', 'All Pred-probs' ])\n",
    "dff"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}