{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " #!nvidia-smi\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS connecting to Cloudant db github-public-ai-2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/anaconda3/envs/crawler/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.cloudant_utils import cloudant_db as db\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from torch import nn\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from prepare_sequence import prepareSequenceForBERT\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "MAX_LEN = 512\n",
    "EPOCHS = 10\n",
    "RANDOM_SEED = 42\n",
    "model_name = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# len(new_df.iloc[1]['readme']), prepareSequenceForBERT(new_df.iloc[1]['readme'][:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = [r for r in db.get_query_result({\"type\": \"release\"}, [\"_id\", \"releases\"], limit=10000, raw_result=True)[\"docs\"]]\n",
    "values = [r for release in repos for r in release[\"releases\"]]\n",
    "df = pd.DataFrame(values)\n",
    "df['contributors'] = df['contributors'].apply(lambda x:\n",
    "                                              [i for i in x if i is not None] if isinstance(x, list)\n",
    "                                              else [])\n",
    "df = df[~df['readme'].isnull()]\n",
    "new_df = df.groupby(\"repo\").agg({\"readme\": list,\n",
    "                                 \"total_stars\": list,\n",
    "#                                  \"forks\": sum,\n",
    "#                                  \"downloads\": sum,\n",
    "#                                  \"contributors\": sum\n",
    "#                                  \"releases\": count\n",
    "                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df[new_df['readme'].map(len) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['k'] = new_df['total_stars'].map(lambda x: random.randint(2, len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['readme1'] = new_df.apply(lambda x: x.readme[:x.k], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['target_val'] = new_df.apply(lambda x: x.total_stars[x.k-1], axis=1)\n",
    "new_df['target'] = new_df.apply(lambda x: 1 if x.target_val> 300 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['sequence']= new_df['readme1'].apply(prepareSequenceForBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readme</th>\n",
       "      <th>total_stars</th>\n",
       "      <th>k</th>\n",
       "      <th>readme1</th>\n",
       "      <th>target</th>\n",
       "      <th>sequence</th>\n",
       "      <th>target_val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>repo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100/Solid</th>\n",
       "      <td>[# Metaheuristics-library-placeholder\\n\\n## Cu...</td>\n",
       "      <td>[490, 550]</td>\n",
       "      <td>2</td>\n",
       "      <td>[# Metaheuristics-library-placeholder\\n\\n## Cu...</td>\n",
       "      <td>1</td>\n",
       "      <td>[CLS], which always returns the best solution ...</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10up/classifai</th>\n",
       "      <td>[## Klasifai\\n\\nClassify WordPress Content usi...</td>\n",
       "      <td>[67, 67, 67, 67, 67, 67, 77, 77, 125, 219, 286]</td>\n",
       "      <td>6</td>\n",
       "      <td>[## Klasifai\\n\\nClassify WordPress Content usi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS]'s,] \\nSupports Watson's Categories, Keyw...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1adrianb/face-alignment</th>\n",
       "      <td>[# Face Recognition\\n\\nDetect facial landmarks...</td>\n",
       "      <td>[3299, 3299, 4005, 4153, 4437, 4452, 4452, 445...</td>\n",
       "      <td>6</td>\n",
       "      <td>[# Face Recognition\\n\\nDetect facial landmarks...</td>\n",
       "      <td>1</td>\n",
       "      <td>[CLS][SEP]1.[SEP][SEP]. Support for Python 2.7...</td>\n",
       "      <td>4452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1adrianb/pytorch-estimate-flops</th>\n",
       "      <td>[# pytorch-estimate-flops\\n\\nSimple pytorch ut...</td>\n",
       "      <td>[51, 51, 53, 81, 94, 98, 117, 174]</td>\n",
       "      <td>5</td>\n",
       "      <td>[# pytorch-estimate-flops\\n\\nSimple pytorch ut...</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS]\\nIgnoring certain layers:\\n```python\\nim...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259mit/AirInteract</th>\n",
       "      <td>[# AirInteract\\n\\nA No-code one stop platform ...</td>\n",
       "      <td>[3, 3, 3, 5]</td>\n",
       "      <td>3</td>\n",
       "      <td>[# AirInteract\\n\\nA No-code one stop platform ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS]\\nInstallation\\nClone the repo\\nInstall r...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2Bear/othello-zero</th>\n",
       "      <td>[# othello-zero\\n\\n## About\\n\\n**othello-zero*...</td>\n",
       "      <td>[8, 12]</td>\n",
       "      <td>2</td>\n",
       "      <td>[# othello-zero\\n\\n## About\\n\\n**othello-zero*...</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS]checkpoint File\\nThe checkpoint file is j...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42-AI/bootcamp_machine-learning</th>\n",
       "      <td>[&lt;p align=\"center\"&gt;\\n  &lt;img src=\"assets/logo_v...</td>\n",
       "      <td>[143, 146, 148, 150, 150, 152, 152, 152, 152]</td>\n",
       "      <td>4</td>\n",
       "      <td>[&lt;p align=\"center\"&gt;\\n  &lt;img src=\"assets/logo_v...</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS]Download\\nThe pdf files of each module ca...</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42-AI/bootcamp_python</th>\n",
       "      <td>[&lt;p align=\"center\"&gt;\\n  &lt;img src=\"assets/logo_v...</td>\n",
       "      <td>[194, 278, 284]</td>\n",
       "      <td>2</td>\n",
       "      <td>[&lt;p align=\"center\"&gt;\\n  &lt;img src=\"assets/logo_v...</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS] Thanks to Ilyes and Kévin for the PR\\nIl...</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4paradigm/AutoX</th>\n",
       "      <td>[# AutoX是什么？\\nAutoX一个高效的自动化机器学习工具，它主要针对于表格类型的数...</td>\n",
       "      <td>[221, 221, 221, 221, 221, 221, 221, 221, 221, ...</td>\n",
       "      <td>13</td>\n",
       "      <td>[# AutoX是什么？\\nAutoX一个高效的自动化机器学习工具，它主要针对于表格类型的数...</td>\n",
       "      <td>0</td>\n",
       "      <td>[CLS][SEP]type | data_,(link), |, |regression,...</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4paradigm/OpenMLDB</th>\n",
       "      <td>[\\n&lt;div align=center&gt;&lt;img src=\"./images/openml...</td>\n",
       "      <td>[133, 383, 677, 957, 966, 1105, 1109, 1115, 11...</td>\n",
       "      <td>8</td>\n",
       "      <td>[\\n&lt;div align=center&gt;&lt;img src=\"./images/openml...</td>\n",
       "      <td>1</td>\n",
       "      <td>[CLS] ,\\ntry a another image (mirror.baidubce....</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            readme  \\\n",
       "repo                                                                                 \n",
       "100/Solid                        [# Metaheuristics-library-placeholder\\n\\n## Cu...   \n",
       "10up/classifai                   [## Klasifai\\n\\nClassify WordPress Content usi...   \n",
       "1adrianb/face-alignment          [# Face Recognition\\n\\nDetect facial landmarks...   \n",
       "1adrianb/pytorch-estimate-flops  [# pytorch-estimate-flops\\n\\nSimple pytorch ut...   \n",
       "259mit/AirInteract               [# AirInteract\\n\\nA No-code one stop platform ...   \n",
       "2Bear/othello-zero               [# othello-zero\\n\\n## About\\n\\n**othello-zero*...   \n",
       "42-AI/bootcamp_machine-learning  [<p align=\"center\">\\n  <img src=\"assets/logo_v...   \n",
       "42-AI/bootcamp_python            [<p align=\"center\">\\n  <img src=\"assets/logo_v...   \n",
       "4paradigm/AutoX                  [# AutoX是什么？\\nAutoX一个高效的自动化机器学习工具，它主要针对于表格类型的数...   \n",
       "4paradigm/OpenMLDB               [\\n<div align=center><img src=\"./images/openml...   \n",
       "\n",
       "                                                                       total_stars  \\\n",
       "repo                                                                                 \n",
       "100/Solid                                                               [490, 550]   \n",
       "10up/classifai                     [67, 67, 67, 67, 67, 67, 77, 77, 125, 219, 286]   \n",
       "1adrianb/face-alignment          [3299, 3299, 4005, 4153, 4437, 4452, 4452, 445...   \n",
       "1adrianb/pytorch-estimate-flops                 [51, 51, 53, 81, 94, 98, 117, 174]   \n",
       "259mit/AirInteract                                                    [3, 3, 3, 5]   \n",
       "2Bear/othello-zero                                                         [8, 12]   \n",
       "42-AI/bootcamp_machine-learning      [143, 146, 148, 150, 150, 152, 152, 152, 152]   \n",
       "42-AI/bootcamp_python                                              [194, 278, 284]   \n",
       "4paradigm/AutoX                  [221, 221, 221, 221, 221, 221, 221, 221, 221, ...   \n",
       "4paradigm/OpenMLDB               [133, 383, 677, 957, 966, 1105, 1109, 1115, 11...   \n",
       "\n",
       "                                  k  \\\n",
       "repo                                  \n",
       "100/Solid                         2   \n",
       "10up/classifai                    6   \n",
       "1adrianb/face-alignment           6   \n",
       "1adrianb/pytorch-estimate-flops   5   \n",
       "259mit/AirInteract                3   \n",
       "2Bear/othello-zero                2   \n",
       "42-AI/bootcamp_machine-learning   4   \n",
       "42-AI/bootcamp_python             2   \n",
       "4paradigm/AutoX                  13   \n",
       "4paradigm/OpenMLDB                8   \n",
       "\n",
       "                                                                           readme1  \\\n",
       "repo                                                                                 \n",
       "100/Solid                        [# Metaheuristics-library-placeholder\\n\\n## Cu...   \n",
       "10up/classifai                   [## Klasifai\\n\\nClassify WordPress Content usi...   \n",
       "1adrianb/face-alignment          [# Face Recognition\\n\\nDetect facial landmarks...   \n",
       "1adrianb/pytorch-estimate-flops  [# pytorch-estimate-flops\\n\\nSimple pytorch ut...   \n",
       "259mit/AirInteract               [# AirInteract\\n\\nA No-code one stop platform ...   \n",
       "2Bear/othello-zero               [# othello-zero\\n\\n## About\\n\\n**othello-zero*...   \n",
       "42-AI/bootcamp_machine-learning  [<p align=\"center\">\\n  <img src=\"assets/logo_v...   \n",
       "42-AI/bootcamp_python            [<p align=\"center\">\\n  <img src=\"assets/logo_v...   \n",
       "4paradigm/AutoX                  [# AutoX是什么？\\nAutoX一个高效的自动化机器学习工具，它主要针对于表格类型的数...   \n",
       "4paradigm/OpenMLDB               [\\n<div align=center><img src=\"./images/openml...   \n",
       "\n",
       "                                 target  \\\n",
       "repo                                      \n",
       "100/Solid                             1   \n",
       "10up/classifai                        0   \n",
       "1adrianb/face-alignment               1   \n",
       "1adrianb/pytorch-estimate-flops       0   \n",
       "259mit/AirInteract                    0   \n",
       "2Bear/othello-zero                    0   \n",
       "42-AI/bootcamp_machine-learning       0   \n",
       "42-AI/bootcamp_python                 0   \n",
       "4paradigm/AutoX                       0   \n",
       "4paradigm/OpenMLDB                    1   \n",
       "\n",
       "                                                                          sequence  \\\n",
       "repo                                                                                 \n",
       "100/Solid                        [CLS], which always returns the best solution ...   \n",
       "10up/classifai                   [CLS]'s,] \\nSupports Watson's Categories, Keyw...   \n",
       "1adrianb/face-alignment          [CLS][SEP]1.[SEP][SEP]. Support for Python 2.7...   \n",
       "1adrianb/pytorch-estimate-flops  [CLS]\\nIgnoring certain layers:\\n```python\\nim...   \n",
       "259mit/AirInteract               [CLS]\\nInstallation\\nClone the repo\\nInstall r...   \n",
       "2Bear/othello-zero               [CLS]checkpoint File\\nThe checkpoint file is j...   \n",
       "42-AI/bootcamp_machine-learning  [CLS]Download\\nThe pdf files of each module ca...   \n",
       "42-AI/bootcamp_python            [CLS] Thanks to Ilyes and Kévin for the PR\\nIl...   \n",
       "4paradigm/AutoX                  [CLS][SEP]type | data_,(link), |, |regression,...   \n",
       "4paradigm/OpenMLDB               [CLS] ,\\ntry a another image (mirror.baidubce....   \n",
       "\n",
       "                                 target_val  \n",
       "repo                                         \n",
       "100/Solid                               550  \n",
       "10up/classifai                           67  \n",
       "1adrianb/face-alignment                4452  \n",
       "1adrianb/pytorch-estimate-flops          94  \n",
       "259mit/AirInteract                        3  \n",
       "2Bear/othello-zero                       12  \n",
       "42-AI/bootcamp_machine-learning         150  \n",
       "42-AI/bootcamp_python                   278  \n",
       "4paradigm/AutoX                         221  \n",
       "4paradigm/OpenMLDB                     1115  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS][SEP]1.[SEP][SEP]. Support for Python 2.7 is deprecated.[SEP], BlazeFace,,Please check the pytorch readme for this.\\nGet the Face Alignment source code\\nbash\\ngit clone \\n,. If you plan to add a new features please open an issue to discuss this prior to making a pull request[SEP]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.iloc[2]['sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7\n",
       "1    3\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ReadmeDataSet(Dataset):\n",
    "   def __init__(self, _df, tokenizer, max_len):\n",
    "      self._df = _df\n",
    "      self.tokenizer = tokenizer\n",
    "      self.max_len = max_len\n",
    "\n",
    "   def __len__(self):\n",
    "      return len(self._df)\n",
    "\n",
    "   def __getitem__(self, item):\n",
    "      _sequence = self._df.iloc[item]['sequence']\n",
    "      target = self._df.iloc[item]['target']\n",
    "      encoding = self.tokenizer.encode_plus(_sequence,\n",
    "                                     None,\n",
    "                                     max_length = self.max_len,\n",
    "                                     truncation=True,\n",
    "                                     add_special_tokens=True,\n",
    "#                                      padding=MAX_LEN,\n",
    "#                                      padding='longest',\n",
    "                                     pad_to_max_length=True,\n",
    "                                     return_token_type_ids=True)\n",
    "\n",
    "      return {\n",
    "      'sequence': _sequence,\n",
    "      'input_ids': torch.tensor(encoding.input_ids, dtype=torch.long),\n",
    "      'attention_mask':  torch.tensor(encoding.attention_mask, dtype=torch.long),\n",
    "      'token_type_ids': torch.tensor(encoding.token_type_ids, dtype=torch.long),\n",
    "      'targets': torch.tensor(target, dtype=torch.long)\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_data_loader(_df, tokenizer, max_len, batch_size):\n",
    "   ds = ReadmeDataSet(_df = _df, tokenizer=tokenizer, max_len=max_len)\n",
    "   return DataLoader(ds, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Import BERT Tokenizer and BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "bert_model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
    "                                                      num_labels=2,\n",
    "                                                      output_attentions= False,\n",
    "                                                      output_hidden_states= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "df_train, df_test = train_test_split(new_df, test_size=0.4, random_state=RANDOM_SEED)\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data_loader = create_data_loader(df_train, bert_tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, bert_tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, bert_tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "new_df.shape, df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for d in train_data_loader:\n",
    "#     input_ids = d[\"input_ids\"].to(device)\n",
    "#     attention_mask = d[\"attention_mask\"].to(device)\n",
    "#     targets = d[\"targets\"].to(device)\n",
    "    print(d[\"sequence\"])\n",
    "    print(d[\"input_ids\"].shape)\n",
    "    print(d[\"targets\"])\n",
    "# len(val_data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TEST the tokenizer and data loader\n",
    "# sequence =prepareSequenceForBERT(new_df.iloc[1]['readme'][:7])\n",
    "# label = new_df.iloc[1]['total_stars'][6]\n",
    "# tokens = bert_tokenizer.encode_plus(\n",
    "#             sequence,\n",
    "#             None,\n",
    "#             max_length= 512,\n",
    "#             truncation=True,\n",
    "#             add_special_tokens=True,\n",
    "# #             pad_to_max_length=True,\n",
    "#             padding = True,\n",
    "#             return_token_type_ids=True\n",
    "#         )\n",
    "# print(f' Sentence: {sequence}')\n",
    "# print(f' Tokens: {tokens}')\n",
    "# print(f' Tokens.token_type_ids: {tokens.token_type_ids}')\n",
    "# print(f' Tokens.input_ids: {len(tokens.input_ids)}')\n",
    "# output = {\n",
    "#       'input_ids': torch.tensor(tokens.input_ids, dtype=torch.long),\n",
    "#       'attention_mask':  torch.tensor(tokens.attention_mask, dtype=torch.long),\n",
    "#       'token_type_ids': torch.tensor(tokens.token_type_ids, dtype=torch.long),\n",
    "#       'targets': torch.tensor(label, dtype=torch.long)\n",
    "#     }\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(bert_model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "bert_model = bert_model.to(device)\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "# loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch( model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "  model = model.train()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  for d in data_loader:\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    targets = d[\"targets\"].to(device)\n",
    "\n",
    "    outputs = model(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask=attention_mask\n",
    "    )\n",
    "\n",
    "    _, preds = torch.max(outputs.logits, dim=1)\n",
    "    loss = loss_fn(outputs.logits, targets)\n",
    "\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  model = model.eval()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "      )\n",
    "      _, preds = torch.max(outputs.logits, dim=1)\n",
    "\n",
    "      loss = loss_fn(outputs.logits, targets)\n",
    "\n",
    "      correct_predictions += torch.sum(preds == targets)\n",
    "      losses.append(loss.item())\n",
    "\n",
    "  return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = defaultdict(list)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    bert_model,\n",
    "    train_data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    len(df_train)\n",
    "  )\n",
    "\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "  val_acc, val_loss = eval_model(\n",
    "    bert_model,\n",
    "    val_data_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(df_val)\n",
    "  )\n",
    "\n",
    "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "  print()\n",
    "\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "\n",
    "  if val_acc > best_accuracy:\n",
    "    current_time = datetime.now().strftime(\"%Y_%m_%d-%I_%M%p\")\n",
    "    torch.save(bert_model.state_dict(), 'best_model_state' + current_time+'.bin')\n",
    "    best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_acc, _ = eval_model(bert_model, test_data_loader, loss_fn, device, len(df_test))\n",
    "test_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "  model = model.eval()\n",
    "\n",
    "  sequences = []\n",
    "  predictions = []\n",
    "  prediction_probs = []\n",
    "  real_values = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "\n",
    "      texts = d[\"sequence\"]\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      token_type_ids = d[\"token_type_ids\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "\n",
    "      outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "\n",
    "      _, preds = torch.max(outputs.logits, dim=1)\n",
    "      probs = F.softmax(outputs.logits, dim=1)\n",
    "\n",
    "      sequences.extend(texts)\n",
    "      predictions.extend(preds)\n",
    "      prediction_probs.extend(probs)\n",
    "      real_values.extend(targets)\n",
    "\n",
    "  predictions = torch.stack(predictions).cpu()\n",
    "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "  real_values = torch.stack(real_values).cpu()\n",
    "  return outputs, sequences, predictions, prediction_probs, real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outputss, y_sequences, y_pred, y_pred_probs, y_test = get_predictions(bert_model, val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "fpr, tpr, thresholds = roc_curve(y_test.numpy(), y_pred_probs[:, 1].numpy())\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=' (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC_'+ current_time +'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_probs_pd = [y.numpy() for y in y_pred_probs]\n",
    "someListOfLists = list(zip(y_sequences, y_test.numpy(), y_pred.numpy(), y_pred_probs[:, 1:].numpy().squeeze(), y_pred_probs_pd ))\n",
    "npa = np.asarray(someListOfLists)\n",
    "dff = pd.DataFrame(someListOfLists, columns = ['readme', 'Real', 'Predicted', 'Pred-prob', 'All Pred-probs' ])\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawler",
   "language": "python",
   "name": "crawler"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
